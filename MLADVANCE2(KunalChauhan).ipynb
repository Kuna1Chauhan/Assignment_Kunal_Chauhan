{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.classification import LogisticRegression\n",
        "from pyspark.ml import Pipeline\n",
        "\n",
        "# Create a SparkSession\n",
        "spark = SparkSession.builder.appName('ChemicalLabeling').getOrCreate()\n",
        "\n",
        "# Load the dataset\n",
        "data = spark.read.csv('https://raw.githubusercontent.com/Kuna1Chauhan/EDA/main/indian_liver_patient.csv', header=True, inferSchema=True)\n",
        "\n",
        "# Data preprocessing\n",
        "data = data.dropna()  # Remove rows with missing values\n",
        "data = data.withColumnRenamed('Dataset', 'label')  # Rename the target column to 'label'\n",
        "\n",
        "# Feature engineering\n",
        "feature_cols = ['Age', 'Total_Bilirubin', 'Albumin_and_Globulin_Ratio']\n",
        "assembler = VectorAssembler(inputCols=feature_cols, outputCol='features')\n",
        "data = assembler.transform(data)\n",
        "\n",
        "# Model training\n",
        "(train_data, test_data) = data.randomSplit([0.8, 0.2], seed=42)  # Split the data into train and test sets\n",
        "lr = LogisticRegression(featuresCol='features', labelCol='label')\n",
        "pipeline = Pipeline(stages=[lr])\n",
        "model = pipeline.fit(train_data)\n",
        "\n",
        "# Model evaluation\n",
        "predictions = model.transform(test_data)\n",
        "accuracy = predictions.filter(predictions.label == predictions.prediction).count() / float(test_data.count())\n",
        "print(f'Accuracy: {accuracy * 100:.2f}%')\n",
        "\n",
        "# Save the model\n",
        "model.save('model')\n",
        "\n",
        "# Close the SparkSession\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "id": "bVHeDQwC2FPe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}